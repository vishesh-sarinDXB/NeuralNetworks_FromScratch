{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (pd.read_csv('2in_complex.txt', names = ['x', 'y', 'z'], delimiter = '\\t'))\n",
    "\n",
    "dataX = np.array(data.drop(columns = 'z'))\n",
    "\n",
    "dataY = np.array(data['z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initWeights(n_layers):\n",
    "    W = list()\n",
    "    for i in range(1, len(n_layers)):\n",
    "        W.append(np.random.randn(n_layers[i], n_layers[i - 1]) * 0.01)\n",
    "    return W\n",
    "\n",
    "def initBiases(n_layers):\n",
    "    B = list()\n",
    "    for i in range(1, len(n_layers)):\n",
    "        B.append(np.zeros(n_layers[i]))\n",
    "    return B\n",
    "\n",
    "def initNetworkX(n_layers):\n",
    "    X = list()\n",
    "    for i in range(len(n_layers)):\n",
    "        X.append(np.zeros(n_layers[i]))\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null(z):\n",
    "    return 0\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def tanH(z):\n",
    "    return np.tanh(z)\n",
    "\n",
    "def cosine(z):\n",
    "    return np.cos(z)\n",
    "\n",
    "def gaussian(z):\n",
    "    return np.exp(-(np.square(z) / 2))\n",
    "\n",
    "vNull = np.vectorize(null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forwardPass(X, W, B, act):\n",
    "    \n",
    "    if act == 'sigmoid':\n",
    "        for i in range(len(X)):\n",
    "            if i != (len(X) - 1):\n",
    "                XWB = np.dot(W[i], X[i]) + B[i]\n",
    "                X[i + 1] = sigmoid(XWB)\n",
    "            else:\n",
    "                return X[-1]\n",
    "                \n",
    "    elif act == 'tanh':\n",
    "        for i in range(len(X)):\n",
    "            if i != (len(X) - 1):\n",
    "                XWB = np.dot(W[i], X[i]) + B[i]\n",
    "                X[i + 1] = tanH(XWB)\n",
    "            else:\n",
    "                return X[-1]\n",
    "                \n",
    "    elif act == 'cos':\n",
    "        for i in range(len(X)):\n",
    "            if i != (len(X) - 1):\n",
    "                XWB = np.dot(W[i], X[i]) + B[i]\n",
    "                X[i + 1] = cosine(XWB)\n",
    "            else:\n",
    "                return X[-1]\n",
    "\n",
    "    elif act == 'gaussian':\n",
    "        for i in range(len(X)):\n",
    "            if i != (len(X) - 1):\n",
    "                XWB = np.dot(W[i], X[i]) + B[i]\n",
    "                X[i + 1] = gaussian(XWB)\n",
    "            else:\n",
    "                return X[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(y_pred, y_true):\n",
    "    return np.square(np.subtract(y_true,y_pred)).mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneEpochLoss(W, B, data, y_true, act):\n",
    "    val_pred = list()\n",
    "    X = initNetworkX(n_layers)\n",
    "    for row in data:\n",
    "        X = initNetworkX(n_layers)\n",
    "        X[0] = row\n",
    "        val_pred.append(forwardPass(X, W, B, act))\n",
    "    return MSE(np.array(val_pred), y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initvWeights(n_layers):\n",
    "    W = list()\n",
    "    for i in range(1, len(n_layers)):\n",
    "        W.append(np.random.uniform(low=-1, high=1, size=(n_layers[i], n_layers[i - 1])))\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initvBiases(n_layers):\n",
    "    W = list()\n",
    "    for i in range(1, len(n_layers)):\n",
    "        W.append(np.random.uniform(low=-10, high=10, size=(n_layers[i])))\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeParticle(n_layers):\n",
    "    W = initvWeights(n_layers)\n",
    "    B = initBiases(n_layers)\n",
    "    vW = initvWeights(n_layers)\n",
    "    vB = initvBiases(n_layers)\n",
    "    return W, B, vW, vB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeSwarm(nP, n_layers):#nSS, n_layers):\n",
    "    S = list()\n",
    "    for i in range(nP):\n",
    "        S.append(makeParticle(n_layers))#nSS, n_layers))\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swarmFitness(S, act):\n",
    "    E = list()\n",
    "    for p in S:\n",
    "        E.append(oneEpochLoss(p[0], p[1], dataX, dataY, act))\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestParticle(E):\n",
    "    return E.index(min(E))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bcd(beta, gamma, delta, shape):\n",
    "    b = np.random.uniform(low=0, high=beta, size=shape)\n",
    "    c = np.random.uniform(low=0, high=gamma, size=shape)\n",
    "    d = np.random.uniform(low=0, high=delta, size=shape)\n",
    "    return b, c, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickInformants(E, S, informants):\n",
    "    I = list()\n",
    "    eI = list()\n",
    "    idx = list()\n",
    "    \n",
    "    for informers in range(informants):\n",
    "        idx.append(np.random.choice(range(len(S))))\n",
    "\n",
    "    for ids in idx:\n",
    "        I.append(S[ids])\n",
    "        eI.append(E[ids])\n",
    "    \n",
    "    return eI, I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainLoop(maxIter, cutoff, activation, informants, E_curr, E_best, S_curr, S_best):\n",
    "    \n",
    "    for iterations in range(maxIter):\n",
    "        \n",
    "        E_curr = swarmFitness(S_curr, activation)\n",
    "        \n",
    "        for i in range(len(E_curr)):\n",
    "            if E_curr[i] < E_best[i]:\n",
    "                E_best[i] = E_curr[i]\n",
    "                S_best[i] = S_curr[i]\n",
    "\n",
    "        if min(E_best) == error_cutoff:\n",
    "            return E_best, S_best, E_curr, S_curr\n",
    "\n",
    "        for p in range(len(S_curr)):\n",
    "            bestMe = S_best[p]\n",
    "\n",
    "            bestAll = S_best[bestParticle(E_best)]\n",
    "\n",
    "            eI, I = pickInformants(E_best, S_best, informants)\n",
    "            eIdx = bestParticle(eI)\n",
    "            bestI = I[eIdx]\n",
    "\n",
    "            for w in range(len(S_curr[p][0])):\n",
    "                b, c, d = bcd(beta, gamma, delta, S_curr[p][2][w].shape)\n",
    "                avi = alpha * S_curr[p][2][w]\n",
    "                bx = b * ((bestMe[0][w] - S_curr[p][0][w]))\n",
    "                cx = c * (bestI[0][w] - S_curr[p][0][w])\n",
    "                dx = d * (bestAll[0][w] - S_curr[p][0][w])\n",
    "                S_curr[p][2][w] = avi + bx + cx + dx\n",
    "                S_curr[p][0][w] = S_curr[p][0][w] + (epsilon * S_curr[p][2][w])\n",
    "                \n",
    "            for b in range(len(S_curr[p][1])):\n",
    "                b2, c, d = bcd(beta, gamma, delta, S_curr[p][3][b].shape)\n",
    "                avi = alpha * S_curr[p][3][b]\n",
    "                bx = b2 * ((bestMe[1][b] - S_curr[p][1][b]))\n",
    "                cx = c * (bestI[1][b] - S_curr[p][1][b])\n",
    "                dx = d * (bestAll[1][b] - S_curr[p][1][b])\n",
    "                S_curr[p][3][b] = avi + bx + cx + dx\n",
    "                S_curr[p][1][b] = S_curr[p][1][b] + (epsilon * S_curr[p][3][b])\n",
    "                \n",
    "    return E_best, S_best, E_curr, S_curr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_cutoff = 0.002\n",
    "maxIter = 250\n",
    "i_layers = [len(data.drop(columns = 'z').columns)]\n",
    "o_layers = [1]\n",
    "particlePossibilities = [i for i in range(10, 101)]\n",
    "rndHParams = list()\n",
    "rndOut = list()\n",
    "rndE_best = list()\n",
    "rndE_curr = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-5dc441157d47>:5: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n"
     ]
    }
   ],
   "source": [
    "for i in range(75):\n",
    "    print(i)\n",
    "    n_layers = i_layers + [np.random.choice([2, 3, 4, 5, 6]) for i in range(1, np.random.choice([2, 3, 4, 5]))] + o_layers\n",
    "    beta = np.random.uniform(low = 0, high = 1.33)\n",
    "    gamma = np.random.uniform(low = 0, high = 1.33)\n",
    "    delta = np.random.uniform(low = 0, high = 1.33)\n",
    "    alpha = np.random.uniform(low = 0.2, high = 2)\n",
    "    numParticles = np.random.choice(particlePossibilities)\n",
    "    informants = np.random.choice([i for i in range(10, (numParticles+1))])\n",
    "    epsilon = np.random.uniform(low = 0.2, high = 2)\n",
    "    act = np.random.choice(['sigmoid', 'gaussian', 'tanh', 'cos'])\n",
    "    params = [n_layers, beta, gamma, delta, alpha, numParticles, informants, epsilon, act]\n",
    "    rndHParams.append(params)\n",
    "    S_curr = makeSwarm(numParticles, n_layers)\n",
    "    S_best = S_curr\n",
    "    E_best = swarmFitness(S_best, act)\n",
    "    E_curr = E_best\n",
    "    E_best, S_best, E_curr, S_curr = mainLoop(maxIter, error_cutoff, act, informants, E_curr, E_best, S_curr, S_best)\n",
    "    rndE_best.append(E_best[bestParticle(E_best)])\n",
    "    rndE_curr.append(E_curr[bestParticle(E_curr)])\n",
    "    rndOut.append([E_best, S_best, E_curr, S_curr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1214765364000266"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndE_best[bestParticle(rndE_best)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 5, 2, 4, 2, 1],\n",
       " 0.20132655128594262,\n",
       " 1.1099957893069692,\n",
       " 0.0657399286443541,\n",
       " 0.2796924161325599,\n",
       " 48,\n",
       " 44,\n",
       " 1.69325977230263,\n",
       " 'tanh']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rndHParams[bestParticle(rndE_best)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
